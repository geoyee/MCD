{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! mkdir -p dataset\n",
    "# ! unzip -oq work/PreTrainData.zip -d dataset\n",
    "# ! pip install --upgrade paddleseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "def create_list(gt_folder=\"dataset/Annotations\"):\n",
    "    random.seed(24)\n",
    "    names = os.listdir(gt_folder)\n",
    "    random.shuffle(names)\n",
    "    print(\"Data volume: \", len(names))\n",
    "    with open(\"dataset/train.txt\", \"w\") as tf:\n",
    "        with open(\"dataset/val.txt\", \"w\") as vf:\n",
    "            for idx, name in enumerate(names):\n",
    "                name = name.split(\".\")[0]\n",
    "                if idx < 17:\n",
    "                    vf.write(\"JPEGImages/\" + name + \".jpg Annotations/\" + name + \".png\\n\")\n",
    "                else:\n",
    "                    tf.write(\"JPEGImages/\" + name + \".jpg Annotations/\" + name + \".png\\n\")\n",
    "    print(\"Finished\")\n",
    "\n",
    "# create_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddleseg.transforms as T\n",
    "from paddleseg.datasets import Dataset\n",
    "\n",
    "base_lr = 3e-4\n",
    "train_lens = 200\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "iters = epochs * train_lens // batch_size\n",
    "\n",
    "# 构建训练集\n",
    "train_transforms = [\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomAffine(),\n",
    "    T.RandomRotation(),\n",
    "    T.RandomDistort(),\n",
    "    T.RandomBlur(),\n",
    "    T.Resize(target_size=(480, 320)),\n",
    "    T.Normalize()  # 归一化\n",
    "]\n",
    "train_dataset = Dataset(\n",
    "    transforms=train_transforms,\n",
    "    dataset_root=\"dataset\",\n",
    "    num_classes=2,\n",
    "    mode=\"train\",\n",
    "    train_path=\"dataset/train.txt\",\n",
    "    separator=\" \"\n",
    ")\n",
    "\n",
    "# 构建验证集\n",
    "val_transforms = [\n",
    "    T.Resize(target_size=(480, 320)),\n",
    "    T.Normalize()\n",
    "]\n",
    "val_dataset = Dataset(\n",
    "    transforms=val_transforms,\n",
    "    dataset_root=\"dataset\",\n",
    "    num_classes=2,\n",
    "    mode=\"val\",\n",
    "    val_path=\"dataset/val.txt\",\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for data in train_dataset:\n",
    "    print(data[\"img\"].shape, data[\"label\"].shape)\n",
    "    print(np.unique(data[\"label\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddleseg.models import OCRNet, HRNet_W48\n",
    "from paddleseg.models.losses import MixedLoss, CrossEntropyLoss, LovaszSoftmaxLoss, DiceLoss\n",
    "\n",
    "# 网络\n",
    "model = OCRNet(\n",
    "    num_classes=2,\n",
    "    backbone=HRNet_W48(),\n",
    "    backbone_indices=[0],\n",
    "    pretrained=\"https://bj.bcebos.com/paddleseg/dygraph/cityscapes/ocrnet_hrnetw48_cityscapes_1024x512_160k/model.pdparams\",\n",
    ")\n",
    "\n",
    "# 损失函数\n",
    "losses = {}\n",
    "losses[\"types\"] = [MixedLoss([CrossEntropyLoss(), LovaszSoftmaxLoss(), DiceLoss()], [0.8, 0.2, 1])] * 2\n",
    "losses[\"coef\"] = [1, 0.4]\n",
    "\n",
    "# 学习率及优化器\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(base_lr, decay_steps=iters, end_lr=base_lr / 5)\n",
    "optimizer = paddle.optimizer.AdamW(lr, beta1=0.9, beta2=0.999, weight_decay=0.01, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddleseg.core import train\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    optimizer=optimizer,\n",
    "    save_dir=\"output\",\n",
    "    iters=iters,\n",
    "    batch_size=batch_size,\n",
    "    save_interval=int(iters / 50),\n",
    "    log_iters=10,\n",
    "    num_workers=0,\n",
    "    losses=losses,\n",
    "    use_vdl=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
